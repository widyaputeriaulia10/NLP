{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk #import library nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize #import word_tokenize for tokenizing text into words \n",
    "from nltk.tokenize import sent_tokenize #import sent_tokenize for tokenizing paragraph into sentences\n",
    "from nltk.stem.porter import PorterStemmer #import Porter Stemmer Algorithm \n",
    "from nltk.stem import WordNetLemmatizer #import WordNet lemmatizer \n",
    "from nltk.corpus import stopwords #import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory #import Indonesian Stemmer\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from collections import Counter\n",
    "import re #import regular expression\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = open(\"artikel bahasa inggris.txt\", \"r\")\n",
    "#l = file.read()\n",
    "\n",
    "def sentence_tokenization(s):\n",
    "    sentences_list = sent_tokenize(s)\n",
    "    \n",
    "    return sentences_list\n",
    "\n",
    "#text_inggris = l\n",
    "#sentence_tokenization(text_inggris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#casefolding\n",
    "def casefolding(s):\n",
    "    new_str = s.lower()\n",
    "    \n",
    "    return new_str\n",
    "\n",
    "#text_inggris1 = casefolding(text_inggris)\n",
    "def removeDigit(str):\n",
    "    new_string = re.sub(r\"[,(.)][^:/]\",\" \", str )\n",
    "    return new_string\n",
    "#text_inggris2 = removeDigit(text_inggris1)\n",
    "#print(text_inggris2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "#text_inggris2 = decontracted(text_inggris2)\n",
    "\n",
    "#text_inggris2 = text_inggris2.replace('-','')\n",
    "#text_inggris2 = text_inggris2.replace('?','')\n",
    "#text_inggris2 = text_inggris2.replace(';','')\n",
    "#text_inggris2 = text_inggris2.replace('.','')\n",
    "\n",
    "#text_inggris2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def stopword(str):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(text_inggris2) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]  \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "    return(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming English\n",
    "def stemmingEnglish(str):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    words = word_tokenize(str)\n",
    "    result = list()\n",
    "    for word in words:\n",
    "        result.append(porter_stemmer.stem(word))\n",
    "        \n",
    "    return ' '.join(result)\n",
    "\n",
    "#porter_stemmer = PorterStemmer()\n",
    "\n",
    "# First Word tokenization\n",
    "#nltk_tokens = nltk.word_tokenize(stemming_text)\n",
    "#Next find the roots of the word\n",
    "#for w in nltk_tokens:\n",
    " #      print(\"Actual: %s  Stem: %s\"  % (w,porter_stemmer.stem(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "def lemmatization(str) :\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma = wordnet_lemmatizer.create_stemmer()\n",
    "    return lemma\n",
    "    #return stemmer.stem(str)\n",
    "#nltk_tokens = nltk.word_tokenize(text_inggris2)\n",
    "#for w in nltk_tokens:\n",
    " #      return (\"Actual: %s  Lemma: %s\"  % (w,wordnet_lemmatizer.lemmatize(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos tagging\n",
    "def postag(str):\n",
    "    tok_sentence = nltk.word_tokenize(str)\n",
    "    tagged_sentence = nltk.pos_tag(tok_sentence)\n",
    "    return tagged_sentence\n",
    "#postag(text_inggris2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('antarctica', 'NN'), ('icy', 'NN'), ('empty', 'JJ'), ('desolate', 'NN'), ('cold', 'JJ'), ('words', 'NNS'), ('may', 'MD'), ('use', 'VB'), ('describe', 'NN'), ('always', 'RB'), ('way', 'NN'), ('time', 'NN'), ('great', 'JJ'), ('southern', 'JJ'), ('landmass', 'NN'), ('covered', 'VBD'), ('forests', 'NNS'), ('dinosaurs', 'NNS'), ('roamed', 'VBD'), ('free', 'JJ'), ('could', 'MD'), ('icy', 'VB'), ('wilderness', 'JJ'), ('warm', 'NN'), ('could', 'MD'), ('support', 'VB'), ('earth', 'JJ'), ('gigantic', 'JJ'), ('creatures', 'NNS'), ('understand', 'VBP'), ('go', 'VB'), ('back', 'RB'), ('geological', 'JJ'), ('time', 'NN'), ('antarctica', 'JJ'), ('ice', 'NN'), ('free', 'JJ'), ('cretaceous', 'JJ'), ('period', 'NN'), ('lasting', 'VBG'), ('145', 'CD'), ('66', 'CD'), ('million', 'CD'), ('years', 'NNS'), ('ago', 'RB'), ('long', 'RB'), ('ago', 'RB'), ('may', 'MD'), ('seem', 'VB'), ('unfamiliar', 'RB'), ('know', 'VB'), ('last', 'JJ'), ('age', 'NN'), ('dinosaurs', 'VBD'), ('asteroid', 'JJ'), ('hit', 'NN'), ('earth', 'NN'), ('ended', 'VBD'), ('time', 'NN'), ('planet', 'JJ'), ('time', 'NN'), ('period', 'NN'), ('forests', 'NNS'), ('poles', 'NNS'), ('fossils', 'NNS'), ('trees', 'NNS'), ('coldblooded', 'VBD'), ('reptiles', 'NNS'), ('allowed', 'VBN'), ('scientists', 'NNS'), ('build', 'VBP'), ('picture', 'NN'), ('climate', 'NN'), ('like', 'IN'), ('coldblooded', 'VBN'), ('reptiles', 'NNS'), ('need', 'VBP'), ('warmth', 'JJ'), ('sun', 'NN'), ('survive', 'NN'), ('today', 'NN'), ('see', 'VBP'), ('basking', 'VBG'), ('sun', 'JJ'), ('warm', 'JJ'), ('day', 'NN'), ('poles', 'NNS'), ('sun', 'VBP'), ('disappears', 'NNS'), ('winter', 'JJ'), ('months', 'NNS'), ('must', 'MD'), ('warm', 'VB'), ('enough', 'RB'), ('survive', 'JJ'), ('darkness', 'NN'), ('scientists', 'NNS'), ('also', 'RB'), ('use', 'VBP'), ('shells', 'NNS'), ('fossil', 'JJ'), ('organisms', 'NNS'), ('lived', 'VBD'), ('ocean', 'RP'), ('called', 'VBN'), ('foraminifera', 'NN'), ('understand', 'NN'), ('past', 'IN'), ('climate', 'NN'), ('analysing', 'VBG'), ('chemistry', 'NN'), ('shells', 'NNS'), ('knowing', 'VBG'), ('age', 'NN'), ('intervals', 'NNS'), ('different', 'JJ'), ('species', 'NNS'), ('lived', 'VBD'), ('get', 'VB'), ('estimate', 'JJ'), ('ocean', 'JJ'), ('water', 'NN'), ('temperature', 'NN'), ('time', 'NN'), ('dr', 'JJ'), ('brian', 'JJ'), ('huber', 'NN'), ('smithsonian', 'JJ'), ('museum', 'NN'), ('natural', 'JJ'), ('history', 'NN'), ('investigates', 'NNS'), ('cretaceous', 'JJ'), ('particular', 'JJ'), ('focus', 'NN'), ('deepsea', 'NN'), ('sites', 'VBZ'), ('around', 'IN'), ('antarctica', 'NN'), ('explains', 'VBZ'), ('“', 'JJ'), ('foraminifera', 'NN'), ('provide', 'NN'), ('best', 'JJS'), ('records', 'NNS'), (\"'ve\", 'VBP'), ('got', 'VBN'), ('bottom', 'JJ'), ('dwelling', 'VBG'), ('ones', 'NNS'), ('living', 'VBG'), ('sediments', 'NNS'), ('recording', 'VBG'), ('bottom', 'JJ'), ('ocean', 'JJ'), ('temperatures', 'NNS'), (\"'ve\", 'VBP'), ('got', 'VBN'), ('planktonic', 'JJ'), ('ones', 'NNS'), ('live', 'VBP'), ('top', 'JJ'), ('fifty', 'NN'), ('meters', 'NNS'), ('ocean', 'VBP'), ('recording', 'VBG'), ('atmospheric', 'JJ'), ('temperatures', 'NNS'), ('couple', 'NN'), ('records', 'NNS'), ('time', 'NN'), ('analyse', 'JJ'), ('shells', 'NNS'), ('different', 'JJ'), ('parts', 'NNS'), ('ocean', 'VBP'), ('world', 'NN'), ('get', 'NN'), ('really', 'RB'), ('good', 'JJ'), ('idea', 'NN'), ('evolution', 'NN'), ('climate', 'NN'), ('huber', 'NN'), ('elaborates', 'VBZ'), ('found', 'VBN'), ('southern', 'JJ'), ('ocean', 'NN'), ('around', 'IN'), ('antarctica', 'RB'), ('hard', 'JJ'), ('believe', 'VBP'), ('first', 'RB'), ('seemed', 'VBN'), ('warm', 'JJ'), ('“', 'NN'), ('found', 'VBD'), ('temperatures', 'NNS'), ('30c', 'CD'), ('58', 'CD'), ('degrees', 'NNS'), ('south', 'RB'), ('close', 'RB'), ('antarctic', 'JJ'), ('circle', 'NN'), ('high', 'JJ'), ('temperatures', 'NNS'), ('occurred', 'VBD'), ('middle', 'JJ'), ('cretaceous', 'JJ'), ('known', 'VBN'), ('‘', 'NNP'), ('cretaceous', 'JJ'), ('hothouse', 'NN'), ('’', 'NNP'), ('hot', 'JJ'), ('greenhouse', 'NN'), ('effect', 'NN'), ('caused', 'VBD'), ('increased', 'JJ'), ('carbon', 'NN'), ('dioxide', 'NN'), ('atmosphere', 'RB'), ('happened', 'VBD'), ('cretaceous', 'JJ'), ('create', 'JJ'), ('world', 'NN'), ('trees', 'NNS'), ('dinosaurs', 'VBP'), ('roaming', 'VBG'), ('antarctica', 'NN'), ('unlike', 'IN'), ('barren', 'JJ'), ('ice', 'NN'), ('fields', 'NNS'), ('today', 'NN'), ('huber', 'VBP'), ('explains', 'VBZ'), ('“', 'NNS'), ('know', 'VBP'), ('midcretaceous', 'JJ'), ('particular', 'JJ'), ('much', 'JJ'), ('faster', 'JJR'), ('rates', 'NNS'), ('sea', 'VBP'), ('floor', 'NN'), ('spreading', 'VBG'), ('volcanic', 'JJ'), ('sources', 'NNS'), ('co2', 'VBP'), ('huber', 'NN'), ('colleagues', 'NNS'), ('still', 'RB'), ('investigating', 'VBG'), ('whether', 'IN'), ('‘', 'NN'), ('hothouse', 'NN'), ('’', 'NN'), ('occurred', 'VBD'), ('result', 'NN'), ('major', 'JJ'), ('amount', 'NN'), ('volcanism', 'NN'), ('erupting', 'VBG'), ('co2', 'NN'), ('creating', 'VBG'), ('greenhouse', 'NN'), ('blanket', 'NN'), ('warmed', 'VBD'), ('earth', 'NN'), ('know', 'VB'), ('climate', 'NN'), ('changes', 'NNS'), ('past', 'IN'), ('changing', 'VBG'), ('future', 'JJ'), ('different', 'JJ'), ('compared', 'VBN'), ('happened', 'VBD'), ('cretaceous', 'JJ'), ('could', 'MD'), ('antarctica', 'VB'), ('icefree', 'JJ'), ('soon', 'RB'), ('“', 'NNP'), (\"'s\", 'POS'), ('really', 'RB'), ('unprecedented', 'JJ'), ('rate', 'NN'), ('magnitude', 'NN'), ('change', 'NN'), ('compared', 'VBN'), ('geologic', 'JJ'), ('events', 'NNS'), ('know', 'VBP'), ('past', 'JJ'), (\"'re\", 'VBP'), ('releasing', 'VBG'), ('hundreds', 'NNS'), ('billions', 'NNS'), ('tons', 'NNS'), ('co2', 'VBP'), ('atmosphere', 'RB'), ('matter', 'RB'), ('decades', 'NNS'), ('volcanoes', 'NNS'), ('ca', 'MD'), (\"n't\", 'RB'), ('produce', 'VB'), ('amount', 'NN'), ('co2', 'VB'), ('short', 'JJ'), ('time', 'NN'), ('span', 'VBD'), ('even', 'RB'), ('huge', 'JJ'), ('volcanoes', 'NNS'), ('”', 'VBP'), ('says', 'VBZ'), ('huber', 'NN'), ('terms', 'NNS'), ('future', 'JJ'), ('huber', 'NN'), ('suggests', 'VBZ'), ('“', 'RB'), ('think', 'VBP'), (\"'ll\", 'MD'), ('see', 'VB'), ('possibly', 'RB'), ('decades', 'NNS'), ('maybe', 'RB'), ('centuries', 'NNS'), ('called', 'VBN'), ('ice', 'NN'), ('streams', 'NNS'), ('start', 'VBP'), ('flowing', 'VBG'), ('faster', 'NN'), ('could', 'MD'), ('west', 'VB'), ('antarctica', 'JJ'), ('particular', 'JJ'), ('starts', 'NNS'), ('deglaciate', 'VB'), ('given', 'VBN'), ('rate', 'NN'), ('ice', 'NN'), ('flows', 'VBZ'), ('wo', 'MD'), (\"n't\", 'RB'), ('see', 'VB'), ('[', 'JJ'), ('whole', 'JJ'), (']', 'NN'), ('antarctica', 'NN'), ('deglaciate', 'VBP'), ('matter', 'NN'), ('decades', 'NNS'), ('glaciologists', 'NNS'), ('predict', 'VBP'), ('start', 'NN'), ('raising', 'VBG'), ('sea', 'NN'), ('level', 'JJ'), ('start', 'NN'), ('getting', 'VBG'), ('positive', 'JJ'), ('feedback', 'NN'), ('allows', 'VBZ'), ('ice', 'NN'), ('flow', 'NN'), ('faster', 'RBR'), ('sea', 'NN'), ('level', 'NN'), ('rises', 'VBZ'), ('faster', 'RBR'), ('sort', 'NN'), ('keeps', 'VBZ'), ('going', 'VBG'), ('yes', 'RB'), ('think', 'VB'), ('signs', 'NNS'), ('already', 'RB'), ('may', 'MD'), ('dinosaurs', 'VB'), ('roaming', 'VBG'), ('antarctica', 'JJ'), ('rule', 'NN'), ('ice', 'RB'), ('free', 'JJ'), ('future', 'JJ'), ('way', 'NN'), ('knowing', 'VBG'), ('would', 'MD'), ('like', 'VB'), ('humans', 'NNS'), ('never', 'RB'), ('lived', 'VBD'), ('earth', 'JJ'), ('ice', 'NN'), ('poles', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file = open('artikel bahasa inggris.txt', 'r')\n",
    "    text_data = file.read()\n",
    "    token = sentence_tokenization(text_data)\n",
    "    text_data = re.sub(r'\\([^)]*\\)', '', text_data)\n",
    "    casefold = casefolding(text_data)\n",
    "    rmvdigit = removeDigit(casefold)\n",
    "    stemming_text = stemmingIndo(casefold)\n",
    "    stemming_textrep = stemming_text.replace('-','')\n",
    "    str1 = ' '.join(filtered_sentence)\n",
    "    pt = postag(str1)\n",
    "    hitung = Counter(filtered_sentence)\n",
    "    print(pt)\n",
    "    \n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
